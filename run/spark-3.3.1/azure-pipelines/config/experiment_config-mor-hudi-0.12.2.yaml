# Description: Experiment Configuration
---
version: 1
id: "${EXP_NAME}"
repetitions: 1
# Metadata accepts any key-value that we want to register together with the experiment run.
metadata:
  system: spark
  system_version: 3.3.1
  table_format: hudi
  table_format_version: 0.12.2
  scale_factor: "${EXP_SCALE_FACTOR}"
  mode: mor
  machine: "${EXP_MACHINE}"
  cluster_size: "${EXP_CLUSTER_SIZE}"
# The following parameter values will be used to replace the variables in the workload statements.
parameter_values:
  external_catalog: spark_catalog
  external_database: "external_tpcds_sf_${EXP_SCALE_FACTOR}"
  external_table_format: csv
  external_data_path: "abfss://azure-pipelines@lstbenchdatasets.dfs.core.windows.net/tpc-ds/csv/sf_${EXP_SCALE_FACTOR}/"
  external_options_suffix: ',header="true"'
  external_tblproperties_suffix: ''
  catalog: spark_catalog
  database: "${EXP_NAME}"
  table_format: hudi
  data_path: 'abfss://azure-pipelines@lstbenchdatasets.dfs.core.windows.net/tpc-ds/run/hudi/sf_${EXP_SCALE_FACTOR}/'
  options_suffix: ''
  tblproperties_suffix: ', "type"="mor"'
