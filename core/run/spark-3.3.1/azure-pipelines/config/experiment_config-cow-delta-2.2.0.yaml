# Description: Experiment Configuration
---
version: 1
id: "${EXP_NAME}"
repetitions: 1
# Metadata accepts any key-value that we want to register together with the experiment run.
metadata:
  system: spark
  system_version: 3.3.1
  table_format: delta
  table_format_version: 2.2.0
  scale_factor: "${EXP_SCALE_FACTOR}"
  mode: cow
  machine: "${EXP_MACHINE}"
  cluster_size: "${EXP_CLUSTER_SIZE}"
# The following parameter values will be used to replace the variables in the workload statements.
parameter_values:
  external_catalog: spark_catalog
  external_database: "external_tpcds_sf_${EXP_SCALE_FACTOR}"
  external_table_format: csv
  external_data_path: "abfss://${DATA_STORAGE_ACCOUNT_CONTAINER}@${DATA_STORAGE_ACCOUNT}.dfs.core.windows.net/tpc-ds/csv/sf_${EXP_SCALE_FACTOR}/"
  external_options_suffix: ',header="true"'
  external_tblproperties_suffix: ''
  catalog: spark_catalog
  database: "${EXP_NAME}"
  table_format: delta
  data_path: 'abfss://${DATA_STORAGE_ACCOUNT_CONTAINER}@${DATA_STORAGE_ACCOUNT}.dfs.core.windows.net/tpc-ds/run/delta/sf_${EXP_SCALE_FACTOR}/'
  options_suffix: ''
  tblproperties_suffix: ''
